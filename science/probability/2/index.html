<article class="mkdocs-fragment"
         data-title="概率入门"
         data-url="science/probability/2/">
  <h1 id="_1">概率入门</h1>
<p>以下部分内容来自 <a href="https://oi-wiki.org/"><strong>OI Wiki</strong></a>。</p>
<h2 id="_2">概率论基本概念</h2>
<h3 id="_3">样本空间</h3>
<p>简而言之，样本空间 $\Omega$ 指明随机现象<strong>所有</strong>可能出现的结果。</p>
<p>具体的，一个随机现象中可能发生的不能再细分的结果被称为<strong>样本点</strong>，所有样本点的集合称为<strong>样本空间</strong>，通常用 $\Omega$ 来表示。</p>
<p>二维样本空间的列举，表格法：</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">6</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>1</strong></td>
<td style="text-align: center;">$(1, 1)$</td>
<td style="text-align: center;">$(1, 2)$</td>
<td style="text-align: center;">$(1, 3)$</td>
<td style="text-align: center;">$(1, 4)$</td>
<td style="text-align: center;">$(1, 5)$</td>
<td style="text-align: center;">$(1, 6)$</td>
</tr>
<tr>
<td style="text-align: center;"><strong>2</strong></td>
<td style="text-align: center;">$(2, 1)$</td>
<td style="text-align: center;">$(2, 2)$</td>
<td style="text-align: center;">$(2, 3)$</td>
<td style="text-align: center;">$(2, 4)$</td>
<td style="text-align: center;">$(2, 5)$</td>
<td style="text-align: center;">$(2, 6)$</td>
</tr>
<tr>
<td style="text-align: center;"><strong>3</strong></td>
<td style="text-align: center;">$(3, 1)$</td>
<td style="text-align: center;">$(3, 2)$</td>
<td style="text-align: center;">$(3, 3)$</td>
<td style="text-align: center;">$(3, 4)$</td>
<td style="text-align: center;">$(3, 5)$</td>
<td style="text-align: center;">$(3, 6)$</td>
</tr>
<tr>
<td style="text-align: center;"><strong>4</strong></td>
<td style="text-align: center;">$(4, 1)$</td>
<td style="text-align: center;">$(4, 2)$</td>
<td style="text-align: center;">$(4, 3)$</td>
<td style="text-align: center;">$(4, 4)$</td>
<td style="text-align: center;">$(4, 5)$</td>
<td style="text-align: center;">$(4, 6)$</td>
</tr>
<tr>
<td style="text-align: center;"><strong>5</strong></td>
<td style="text-align: center;">$(5, 1)$</td>
<td style="text-align: center;">$(5, 2)$</td>
<td style="text-align: center;">$(5, 3)$</td>
<td style="text-align: center;">$(5, 4)$</td>
<td style="text-align: center;">$(5, 5)$</td>
<td style="text-align: center;">$(5, 6)$</td>
</tr>
<tr>
<td style="text-align: center;"><strong>6</strong></td>
<td style="text-align: center;">$(6, 1)$</td>
<td style="text-align: center;">$(6, 2)$</td>
<td style="text-align: center;">$(6, 3)$</td>
<td style="text-align: center;">$(6, 4)$</td>
<td style="text-align: center;">$(6, 5)$</td>
<td style="text-align: center;">$(6, 6)$</td>
</tr>
</tbody>
</table>
<h3 id="_4">随机事件</h3>
<p>一个<strong>事件</strong>是样本空间 $\Omega$ 的<strong>任意子集</strong>，又分为：</p>
<ul>
<li>一个<strong>随机事件</strong>是样本空间 $\Omega$ 的<strong>非空真子集</strong>。</li>
<li>一个<strong>必然事件</strong>是样本空间 $\Omega$ 本身。</li>
<li>一个<strong>不可能事件</strong>是一个空集 $\varnothing$。</li>
<li>一个<strong>基本事件</strong>是样本空间 $\Omega$ 的一个大小为 $1$ 的子集。</li>
</ul>
<p>由此可知，事件是一个由若干样本点构成，用大写字母 $A, B, C, \cdots$ 表示。</p>
<p>对于一个随机现象的结果 $\omega$ 和一个随机事件 $A$，我们称事件 $A$ 发生了 当且仅当 $\omega \in A$。</p>
<p>例如：掷一次骰子得到的点数是一个随机现象，其样本空间可以表示为 $\Omega={1,2,3,4,5,6}$。设随机事件 $A$ 为「获得的点数大于 $4$」，则 $A = { 5, 6 }$。若某次掷骰子得到的点数 $\omega = 3$，由于 $\omega \notin A$，故事件 $A$ 没有发生。</p>
<h3 id="_5">事件的运算</h3>
<p>由于我们将随机事件定义为了样本空间 $\Omega$ 的子集，故我们可以将集合的运算（如交、并、补等）移植到随机事件上。记号与集合运算保持一致。</p>
<ul>
<li>并（和）事件：事件的并 $A \cup B$ 也可记作 $A + B$，表示至少有一个事件发生。</li>
<li>交（积）事件：事件的交 $A \cap B$ 也可记作 $AB$，表示事件全部发生。</li>
</ul>
<h2 id="_6">概率的定义和性质</h2>
<h3 id="_7">古典概型</h3>
<p>在概率论早期实践中，由于涉及到的随机现象都比较简单，具体表现为样本空间 $\Omega$ 是有限集，且直观上所有样本点是等可能出现的，因此人们便总结出了下述定义（称为<strong>传统概率模型</strong>或<strong>古典概率模型</strong>或<strong>拉普拉斯概率模型</strong>）：</p>
<p>如果一个随机现象满足：</p>
<ul>
<li>只有有限个基本结果。</li>
<li>每个基本结果出现的<strong>可能性是一样的</strong>。</li>
</ul>
<p>那么对于每个事件 $A$，定义它的概率为：</p>
<p>$$
P(A)=\dfrac{|A|}{|\Omega|}
$$</p>
<p>最经典的例子是，掷硬币、掷骰子。</p>
<p>或者用 $#(\cdot)$ 表示对随机事件（一个集合）大小的度量：</p>
<p>$$
P(A)=\dfrac{#(A)}{#(\Omega)}
$$</p>
<p>古典概型做题公式：</p>
<ol>
<li>
<p>记事件 $A=\dots$。</p>
</li>
<li>
<p>$\Omega={\dots}$ 共几个。</p>
</li>
<li>
<p>$A={\dots}$ 共几个。</p>
</li>
<li>
<p>$P(A)=\dfrac{#(A)}{#(\Omega)}$。</p>
</li>
</ol>
<p>后来人们发现这一定义可以直接推广到 $\Omega$ 无限的一部分情景中，于是就有了所谓几何概型。</p>
<p>在古典概型中，最应当注意的是<strong>一致的可能性</strong>，例如扔两次硬币，一正一反就不应当是一个于两正、两反等概率的事件。</p>
<h3 id="_8">几何概型</h3>
<p>在这个模型下，随机实验所有可能的结果是无限的，并且每个基本结果发生的<strong>概率是相同的</strong>。</p>
<p>几何概型定义，概率 $=$ 有利区域测度 $\div$ 总区域测度。当所求解问题可以转化为某种随机分布的特征数，比如随机事件出现的概率，或者随机变量的期望，就可以使用蒙特卡罗法。</p>
<p>通过大量随机抽样的方法，以随机事件出现的频率估计其概率，或者以抽样的数字特征估算随机变量的数字特征，并将其作为问题的解。</p>
<p>经常的，我们会因为概率相同犯错误，这也导致了 <a href="https://en.wikipedia.org/wiki/Bertrand_paradox_(probability)">Bertrand（伯特兰）悖论</a> 等问题的产生，于是也就诞生了概率的公理化描述。</p>
<h3 id="_9">概率公理</h3>
<p>公理一：$0\le P(A)\le1(A\subset\Omega)$。</p>
<p>公理二：$P(\Omega)=1,P(\varnothing)=0$。</p>
<p>公理三：$A\cap B=\varnothing\iff P(A\cup B)=P(A)+P(B)$。</p>
<p>推论：</p>
<ul>
<li>
<p>若 $A\subset B$，则 $P(A)&lt;P(B)$（概率的单调性）。</p>
</li>
<li>
<p>若 $A$ 与 $B$ 对立，则 $P(A)+P(B)=1$。</p>
</li>
<li>
<p>容斥原理：$P(A\cup B)=P(A)+P(B)-P(A\cap B)$。</p>
</li>
</ul>
<p>其中上面第二条就是容斥原理的推论。</p>
<h3 id="_10">频率学派</h3>
<p>频率学派强调通过数据出现的<strong>频率</strong>或比例，从样本数据中得出结论。</p>
<p>根据大数定律，样本数量越多，则其算术平均值就有越高的概率接近期望。</p>
<p>最经典的例子是，抛硬币正面向上的频率趋近于 $0.5$。</p>
<h3 id="_11">主观概率</h3>
<p>主观概率，是指建立在过去的经验与判断的基础上，根据对未来事态发展的预测和历史统计资料的研究确定的概率。主观概率反映的只是一种主观可能性，尽管有一定的科学性，但和能客观地反映事物发展规律的自然概率不同。</p>
<p>最经典的例子是，降雨概率。</p>
<h2 id="_12">条件概率</h2>
<h3 id="_13">条件概率</h3>
<p>当某事件已经发生时，一些随机事件的概率会因为已知信息的增加发生变化。</p>
<p>若已知事件 $A$ 发生，在此条件下事件 $B$ 发生的概率称为 条件概率，记作 $P(B|A)$。</p>
<p>在样本空间中，若事件 $A$ 满足 $P(A) &gt; 0$，则条件概率 $P(\cdot|A)$ 定义为：</p>
<p>$$
P(B|A) = \frac{P(AB)}{P(A)}
$$</p>
<p>条件概率有时候也称为<strong>后验概率</strong>，与先验概率相对。</p>
<ol>
<li>
<p>$P(\Omega|A)=1$.</p>
</li>
<li>
<p>若 $B,C$ 互斥（$BC=\varnothing$）则：</p>
<p>$$
P(BC)=P(B)+P(C)
$$</p>
<p>$$
P(PC|A)=P(B|A)+P(C|A)
$$</p>
<p>$$
P(\bar B|A)=1-P(B|A)
$$</p>
</li>
</ol>
<p>条件概率的计算有还有三个公式，我们详细讲解。</p>
<h3 id="_14">概率乘法公式</h3>
<p>若 $P(A) &gt; 0$，则对任意事件 $B$ 都有</p>
<p>$$
P(AB) = P(A)P(B|A)
$$</p>
<p>注意到这也就是条件概率的定义式。</p>
<h3 id="_15">全概率公式</h3>
<p>全概率公式指出，对于 $A,B$ 两组对立事件，</p>
<p>$$
P(B)=P(A)P(B|A)+P(\bar A)P(B|\bar A)
$$</p>
<p>可以理解为，$A$ 发生后 $B$ 发生，和 $A$ 不发生但是 $B$ 发生概率之和。</p>
<p>In general，若一组事件 $A_1, \cdots, A_n$ 共同对立（两两不交、互相独立且和为 $\Omega$），则对任意事件 $B$ 都有：</p>
<p>$$
P(B) = \sum_{i=1}^{n} P(A_i)P(B|A_i)
$$</p>
<h3 id="bayes">Bayes 公式</h3>
<p>贝叶斯定理（也成贝氏定理）指出，若 $P(A),P(B)&gt;0$，则：</p>
<p>$$
P(A|B)=\dfrac{P(AB)}{P(B)}=\dfrac{P(A)P(B|A)}{P(B)}
$$</p>
<p>可以理解为将中间的 $P(AB)$ 用概率乘法公式展开，向左向右写出。</p>
<p>也可以将 $P(A)$ 提出来，剩余的部分 $P(B|A)/P(B)$ 称为标准似然度。</p>
<p>带入全概率公式，于是有：</p>
<p>$$
P(A|B)=\dfrac{P(A)P(B|A)}{P(A)P(B|A)+P(\bar A)P(B|\bar A)}
$$</p>
<p>一般来说，设可能导致事件 $B$ 发生的原因为 $A_1, A_2, \cdots, A_n$（同样构成了<strong>互斥</strong>），则在 $P(A_i)$ 和 $P(B|A_i)$ 已知时可以通过全概率公式计算事件 $B$ 发生的概率。但在很多情况下，我们需要根据「事件 $B$ 发生」这一结果反推其各个原因事件的发生概率。</p>
<p>$$
P(A_i|B) = \frac{P(A_iB)}{P(B)} = \frac{P(A_i)P(B|A_i)}{\sum_{j=1}^{n} P(A_j)P(B|A_j)}
$$</p>
<h2 id="_16">事件的独立性</h2>
<h3 id="_17">互斥和对立事件</h3>
<p><strong>互斥事件</strong>：$P(AB)=0$，即有 $A$ 没 $B$ 有 $B$ 没 $A$。</p>
<p>$$
A,B\textsf{ 互斥}\iff AB=\varnothing
$$</p>
<p><strong>对立事件</strong>：其中必有一个发生的两个互斥事件。</p>
<p>$$
A,B\textsf{ 对立}\iff AB=\varnothing,A\cup B=\Omega
$$</p>
<p>对于互斥事件和对立事件（是互斥事件的一个特例）：</p>
<p>$$
P(AB)=P(A)+P(B)
$$</p>
<h3 id="_18">独立事件和独立性</h3>
<p><strong>独立事件</strong>：$A$ 发生不影响 $B$ 而 $B$ 发生也不影响 $A$。</p>
<p>$$
P(AB)=P(A)P(B)
$$</p>
<p>根据这个式子，如果 $A,B$ 独立，那么 $A$ 及其补集，$B$ 及其补集也应当都是独立的。</p>
<p>在条件概率中，若 $A,B$ 独立：</p>
<p>$$
P(A|B)=\dfrac{P(AB)}{P(B)}=P(A)
$$</p>
<p>$$
P(B|A)=\dfrac{P(AB)}{P(A)}=P(B)
$$</p>
<p>也可以用条件概率推导独立，这是 iff 的。</p>
<h3 id="_19">多个事件的独立性</h3>
<p>对于多个事件 $A_1, A_2, \cdots, A_n$，我们称其独立，当且仅当对任意一组事件 ${ A_{i_k} : 1 \leq i_1 &lt; i_2 &lt; \cdots &lt; i_k \leq n }$ 都有：</p>
<p>$$
P( A_{i_1}A_{i_2} \cdots A_{i_r} ) = \prod_{k=1}^{r} P(A_{i_k})
$$</p>
<p>对于多个事件，一般不能从两两独立推出这些事件独立。考虑以下反例：</p>
<ul>
<li>有一个正四面体骰子，其中三面被分别涂成红色、绿色、蓝色，另一面则三色皆有。现在扔一次该骰子，令事件 $A,B,C$ 分别表示与桌面接触的一面包含红色、绿色、蓝色。</li>
</ul>
<p>不难计算：</p>
<p>$$
P(A) = P(B) = P(C) = \frac{1}{2}
$$</p>
<p>$$
P(AB) = P(BC) = P(CA) = P(ABC) = \frac{1}{4}
$$</p>
<p>显然 $A, B, C$ 两两独立，但由于 $P(ABC) \neq P(A)P(B)P(C)$，故 $A, B, C$ 不独立。</p>
<h2 id="_20">概率的应用</h2>
<h3 id="_21">条件概率谬论</h3>
<p>条件概率的谬论是假设 $P(A|B)$ 大致等于 $P(B|A)$。</p>
<p>根据 Bayes 公式：</p>
<p>$$
P(A)P(B|A)=P(B)P(A|B)
$$</p>
<p>最经典的例子是患病概率，考虑到灵敏度、特异度等因素，本文不予讲解，详见 <a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values">Wikipedia</a>。</p>
<!-- 数学 -->
<!-- 物理 -->
<!-- 化学 -->
<!-- 生物 -->
<!-- 教育 -->
<!-- 联合国与国际机构 -->
<!-- 欧洲联盟与地区组织 -->
</article>